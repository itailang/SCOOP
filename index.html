<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description" content="Scene flow estimation from point clouds based on pure correspondence learning and direct refinement optimization.">
  <meta name="keywords" content="SCOOP, Scene Flow, Point Clouds, Self-Supervised, Correspondence, Optimization, CVPR 2023">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" href="./assets/icon_wo_bg.png">

  <title>SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q6JSKPD63W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-Q6JSKPD63W');
  </script>
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow</h1>
          <h2 class="title is-3 publication-conference">CVPR 2023</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <div class="author-portrait">
                <img src="./assets/itai.png" class="rgb preload" alt="Itai">
              </div>
              <a href="https://scholar.google.com/citations?user=q0bBhtsAAAAJ">Itai Lang</a><sup>1,2*</sup>
            </span>
            <span class="author-block">
              <div class="author-portrait">
                <img src="./assets/dror.png" class="rgb preload" alt="Dror">
              </div>
              <a href="https://research.google/people/DrorAiger/">Dror Aiger</a><sup>2</sup>
            </span>
            <span class="author-block">
              <div class="author-portrait">
                <img src="./assets/forrester.png" class="rgb preload" alt="Forrester">
              </div>
              <a href="http://people.csail.mit.edu/fcole/">Forrester Cole</a><sup>2</sup>
            </span>
            <span class="author-block">
              <div class="author-portrait">
                <img src="./assets/shai.png" class="rgb preload" alt="Shai">
              </div>
              <a href="http://www.eng.tau.ac.il/~avidan/">Shai Avidan</a><sup>1</sup>
            </span>
            <span class="author-block">
              <div class="author-portrait">
                <img src="./assets/michael.png" class="rgb preload" alt="Michael">
              </div>
              <a href="http://people.csail.mit.edu/mrub/">Michael Rubinstein</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Tel Aviv University
            </span>
            <span class="author-block">
              &nbsp;&nbsp;&nbsp;<sup>2</sup>Google Research
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <sup>*</sup>The work was done during an internship at Google Research.
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Lang_SCOOP_Self-Supervised_Correspondence_and_Optimization-Based_Scene_Flow_CVPR_2023_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.14020"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=b8MVWGU7V4E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link -->
              <span class="link-block">
                <a href="https://github.com/itailang/SCOOP"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="subtitle has-text-justified">
              SCOOP is a self-supervised scene flow estimation method for 3D point clouds. It is based on pure
              correspondence learning and direct refinement optimization, which enable it to use a fraction
              of the training data while achieving state-of-the-art results.
            </h2>
            <video id="teaser" autoplay controls muted loop playsinline height="100%">
              <source src="./assets/strict_acc_vs_train_set_size.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Scene flow estimation is a long-standing problem in computer vision, where the goal is to find the 3D motion
            of a scene from its consecutive observations. Recently, there have been efforts to compute the scene flow
            from 3D point clouds. A common approach is to train a regression model that consumes source and target point
            clouds and outputs the per-point translation vector. An alternative is to learn point matches between the
            point clouds concurrently with regressing a refinement of the initial correspondence flow. In both cases,
            the learning task is very challenging since the flow regression is done in the free 3D space, and a typical
            solution is to resort to a large annotated synthetic dataset.
          </p>
          <p>
            We introduce SCOOP, a new method for scene flow estimation that can be learned on a small amount of data
            without employing ground-truth flow supervision. In contrast to previous work, we train a pure
            correspondence model focused on learning point feature representation and initialize the flow as the
            difference between a source point and its softly corresponding target point. Then, in the run-time phase,
            we directly optimize a flow refinement component with a self-supervised objective, which leads to a coherent
            and accurate flow field between the point clouds. Experiments on widespread datasets demonstrate the
            performance gains achieved by our method compared to existing leading techniques while using a fraction of
            the training data.
          </p>
        </div>
      </div>
    </div>

    <!-- Publication Video -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/b8MVWGU7V4E?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Key Idea -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Key Idea</h2>
        <div class="content has-text-justified">
          <p>
            Previous methods regress the entire flow in the ambient 3D space, jointly learn correspondence and refinement,
            or optimize the complete flow from scratch separately for each scene. Instead, we replace these challenging
            problems with two simpler ones: training a correspondence model focused only on learning point
            feature representation without any flow regression, and directly optimizing a residual flow refinement at
            the run-time.
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="others" width="100%" src="./assets/approach_others.png" alt="Others">
        </div>
        <div class="content has-text-centered">
          <img id="ours" width="48.5%" src="./assets/approach_ours.png" alt="Ours">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <div class="content has-text-justified">
          <p>
            SCOOP includes two components: a learned point cloud correspondence model and a flow refinement module.
            The model is focused on learning deep point embeddings <strong>&#966;<sub><i>X</i></sub></strong>,
            <strong>&#966;<sub><i>Y</i></sub></strong> to establish soft point matches based on a matching cost
            <strong><i>C</i></strong> in the latent feature space. The initial flow <strong><i>F</i></strong> from the
            training phase is the difference between the softly corresponding point cloud and the source point cloud.
          </p>
          <p>
            At the test-time, we freeze the trained model and directly optimize a residual flow refinement
            <strong><i>R<sup>*</sup></i></strong> to produce a smooth and consistent scene flow
            <strong><i>F<sup>*</sup></i></strong> between the point clouds.
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="system" width="80%" src="./assets/system.png" alt="System">
        </div>

        <div class="content has-text-justified">
          <br>
          <p>
            Our self-supervised losses require that each translated source point has a nearby target point and that
            neighboring source points have similar flow vectors. These two losses result in a coherent flow field that
            warps the source point cloud close to the underlying surface of the target point cloud.
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="losses" width="80%" src="./assets/losses.png" alt="Losses">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            Compared to the popular previous method
            <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730528.pdf">FLOT</a>, SCOOP better
            preserves the structure of the source point cloud and accurately computes its flow.
          </p>
        </div>
        <div class="comparison">
          <img src="./assets/comparison_f_s.png" alt="Comparison" >
          <img src="./assets/comparison_s_f.png" alt="Comparison" class="swap" >
        </div>

        <div class="content has-text-justified">
          <br>
          <br>
          <p>
            SCOOP estimates the scene flow correctly in various challenging cases:
            <br>
            <br>
            Varied point cloud density (cars).
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="results density" width="100%" src="./assets/results_density.png" alt="Density">
        </div>

        <div class="content has-text-justified">
          <p>
            Repetitive structures (fence).
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="results repetitive" width="100%" src="./assets/results_repetitive.png" alt="Density">
        </div>

        <div class="content has-text-justified">
          <p>
            Objects with different motion directions (car and pole) or different geometry and size (pole and facade).
          </p>
        </div>
        <div class="content has-text-centered">
          <img id="results geometry" width="100%" src="./assets/results_different.png" alt="Different">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Citation</h2>
    <pre><code>@InProceedings{lang2023scoop,
  author = {Lang, Itai and Aiger, Dror and Cole, Forrester and Avidan, Shai and Rubinstein, Michael},
  title = {{SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow}},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {5281--5290},
  year = {2023}
}
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2211.14020.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/itailang">
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://scholar.google.com/citations?user=q0bBhtsAAAAJ">
        <i class="ai ai-google-scholar"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            This website is adapted from the <a href="https://nerfies.github.io">Nerfies</a> website. We thank
            <a href="https://keunhong.com">Keunhong Park</a> for sharing his
            <a href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>

</html>